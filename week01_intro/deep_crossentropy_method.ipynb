{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Google Colab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "# import os\n",
    "# if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "#     !bash ../xvfb start\n",
    "#     os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01841745, -0.00090813, -0.03165235, -0.01485597]),\n",
       " array([-0.01841745, -0.00090813, -0.03165235, -0.01485597])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[env.reset()] * n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03243488, -0.03007742, -0.01563043,  0.01233667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba(s.reshape(1, -1))\n",
    "        probs = np.reshape(probs, probs.size)\n",
    "\n",
    "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(probs.size), p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[-0.02435176 -0.02633881  0.03128291 -0.00871133]\n",
      " [-0.02487854  0.16832086  0.03110868 -0.2913623 ]\n",
      " [-0.02151212  0.36298575  0.02528143 -0.57407388]\n",
      " [-0.01425241  0.16751865  0.01379996 -0.27353497]\n",
      " [-0.01090204  0.36244101  0.00832926 -0.56183361]]\n",
      "actions: [1, 1, 0, 1, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([list([array([ 0.0346731 ,  0.04258321, -0.01643595, -0.00045906]), array([ 0.03552476,  0.23793697, -0.01644513, -0.29828208]), array([ 0.0402835 ,  0.43328943, -0.02241078, -0.5961058 ]), array([ 0.04894929,  0.62871773, -0.03433289, -0.89576285]), array([ 0.06152364,  0.43407769, -0.05224815, -0.61406673]), array([ 0.0702052 ,  0.6298893 , -0.06452948, -0.92273731]), array([ 0.08280298,  0.43569575, -0.08298423, -0.65101175]), array([ 0.0915169 ,  0.63186947, -0.09600446, -0.96862908]), array([ 0.10415429,  0.82814011, -0.11537705, -1.28986132]), array([ 0.12071709,  1.0245248 , -0.14117427, -1.61632547]), array([ 0.14120759,  1.22100135, -0.17350078, -1.94947582])]),\n",
       "        list([array([ 0.04998355,  0.02012134,  0.03805684, -0.03431679]), array([ 0.05038598, -0.17552511,  0.03737051,  0.2701264 ]), array([ 0.04687548, -0.37115987,  0.04277304,  0.57435803]), array([ 0.03945228, -0.56685456,  0.0542602 ,  0.88020302]), array([ 0.02811519, -0.37251008,  0.07186426,  0.60506001]), array([ 0.02066499, -0.17846278,  0.08396546,  0.33585026]), array([0.01709573, 0.0153701 , 0.09068246, 0.07078209]), array([ 0.01740313, -0.18092702,  0.0920981 ,  0.39064206]), array([0.01378459, 0.01277538, 0.09991095, 0.12835842]), array([ 0.0140401 ,  0.20633468,  0.10247811, -0.13120764]), array([0.0181668 , 0.00990544, 0.09985396, 0.19196629]), array([ 0.0183649 ,  0.20346767,  0.10369329, -0.06762248]), array([0.02243426, 0.00702371, 0.10234084, 0.25589194]), array([ 0.02257473, -0.1893992 ,  0.10745868,  0.57902041]), array([ 0.01878675, -0.38585   ,  0.11903908,  0.90352897]), array([ 0.01106975, -0.58236568,  0.13710966,  1.23113133]), array([-5.77565833e-04, -3.89247402e-01,  1.61732291e-01,  9.84356545e-01]), array([-0.00836251, -0.58612283,  0.18141942,  1.32315807]), array([-0.02008497, -0.39369617,  0.20788258,  1.09230027])]),\n",
       "        list([array([-0.00637262,  0.01094254,  0.01696972, -0.04180288]), array([-0.00615376,  0.20581709,  0.01613366, -0.32908376]), array([-0.00203742,  0.01046923,  0.00955199, -0.031357  ]), array([-0.00182804, -0.18478839,  0.00892485,  0.26432431]), array([-0.00552381, -0.38003659,  0.01421133,  0.5598088 ]), array([-0.01312454, -0.57535509,  0.02540751,  0.85693497]), array([-0.02463164, -0.38058836,  0.04254621,  0.57234817]), array([-0.03224341, -0.57628025,  0.05399317,  0.87812518]), array([-0.04376901, -0.38193196,  0.07155568,  0.60289384]), array([-0.05140765, -0.57797795,  0.08361355,  0.91722972]), array([-0.06296721, -0.38407996,  0.10195815,  0.65195259]), array([-0.07064881, -0.58046296,  0.1149972 ,  0.97492109]), array([-0.08225807, -0.77692397,  0.13449562,  1.30140091]), array([-0.09779655, -0.97347147,  0.16052364,  1.63298225]), array([-0.11726598, -1.17007288,  0.19318328,  1.97108456])]),\n",
       "        list([array([-0.02006925, -0.00864796,  0.03399207, -0.02262615]), array([-0.02024221,  0.18597044,  0.03353954, -0.30439336]), array([-0.0165228 , -0.00961304,  0.02745168, -0.00132437]), array([-0.01671506, -0.20511771,  0.02742519,  0.29989193]), array([-0.02081742, -0.40061962,  0.03342303,  0.60109651]), array([-0.02882981, -0.59619279,  0.04544496,  0.90411696]), array([-0.04075366, -0.40171483,  0.0635273 ,  0.62605742]), array([-0.04878796, -0.59766334,  0.07604844,  0.93805176]), array([-0.06074123, -0.40364456,  0.09480948,  0.67020144]), array([-0.06881412, -0.59994787,  0.10821351,  0.99116625]), array([-0.08081308, -0.40642743,  0.12803683,  0.73433626]), array([-0.08894162, -0.60306385,  0.14272356,  1.0644166 ]), array([-0.1010029 , -0.41008954,  0.16401189,  0.81971671]), array([-0.10920469, -0.21754636,  0.18040623,  0.58278139]), array([-0.11355562, -0.41467599,  0.19206185,  0.92642917])]),\n",
       "        list([array([-0.04210679,  0.02452042,  0.01789853, -0.03765953]), array([-0.04161638,  0.21938119,  0.01714534, -0.32464198]), array([-0.03722876,  0.02401936,  0.0106525 , -0.02660183]), array([-0.03674837,  0.21898694,  0.01012046, -0.31590483]), array([-0.03236863,  0.02372231,  0.00380237, -0.02004751]), array([-0.03189419, -0.17145397,  0.00340142,  0.27383268]), array([-0.03532327,  0.02361929,  0.00887807, -0.01777549]), array([-0.03485088, -0.17162885,  0.00852256,  0.27769529]), array([-0.03828346, -0.36687134,  0.01407647,  0.573054  ]), array([-0.04562089, -0.17194956,  0.02553755,  0.28483863]), array([-0.04905988,  0.02279903,  0.03123432,  0.00031822]), array([-0.0486039 ,  0.21745944,  0.03124068, -0.28234858]), array([-0.04425471,  0.02190613,  0.02559371,  0.02002152]), array([-0.04381659,  0.21665187,  0.02599414, -0.26447769]), array([-0.03948355,  0.41139334,  0.02070459, -0.54884979]), array([-0.03125568,  0.21598676,  0.00972759, -0.24971602]), array([-0.02693595,  0.02072725,  0.00473327,  0.04601925]), array([-0.0265214 ,  0.21578101,  0.00565366, -0.24516654]), array([-0.02220578,  0.02057877,  0.00075033,  0.04929432]), array([-0.02179421, -0.17455394,  0.00173621,  0.34221388]), array([-0.02528528,  0.02054327,  0.00858049,  0.05007896]), array([-0.02487442,  0.21554114,  0.00958207, -0.23988444]), array([-0.0205636 ,  0.02028363,  0.00478438,  0.05580547]), array([-0.02015792, -0.1749066 ,  0.00590049,  0.34999405]), array([-0.02365605, -0.37011196,  0.01290037,  0.64453174]), array([-0.03105829, -0.17517215,  0.02579101,  0.35593896]), array([-0.03456174,  0.0195738 ,  0.03290979,  0.0714989 ]), array([-0.03417026, -0.17600413,  0.03433976,  0.37438067]), array([-0.03769034, -0.37159661,  0.04182738,  0.67769033]), array([-0.04512228, -0.56727396,  0.05538118,  0.9832433 ]), array([-0.05646776, -0.37293599,  0.07504605,  0.70845702]), array([-0.06392648, -0.56901281,  0.08921519,  1.02378726]), array([-0.07530673, -0.37518504,  0.10969094,  0.76039637]), array([-0.08281043, -0.57163352,  0.12489886,  1.0854826 ]), array([-0.0942431 , -0.76816176,  0.14660852,  1.41460349]), array([-0.10960634, -0.57512862,  0.17490059,  1.17110866]), array([-0.12110891, -0.77203895,  0.19832276,  1.51312703])])],\n",
       "       dtype=object), array([list([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]),\n",
       "        list([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0]),\n",
       "        list([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]),\n",
       "        list([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]),\n",
       "        list([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1])],\n",
       "       dtype=object), array([11., 19., 15., 15., 37.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_batch[:5], actions_batch[:5], rewards_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.04210679,  0.02452042,  0.01789853, -0.03765953]),\n",
       "  array([-0.04161638,  0.21938119,  0.01714534, -0.32464198]),\n",
       "  array([-0.03722876,  0.02401936,  0.0106525 , -0.02660183]),\n",
       "  array([-0.03674837,  0.21898694,  0.01012046, -0.31590483]),\n",
       "  array([-0.03236863,  0.02372231,  0.00380237, -0.02004751])],\n",
       " [1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite_states[:5], elite_actions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    idxs = [idx for idx, x in enumerate(rewards_batch) if x >= reward_threshold]\n",
    "    \n",
    "    elite_states = []\n",
    "    for idx, states in enumerate(states_batch):\n",
    "        if idx in idxs:\n",
    "            elite_states += states\n",
    "    \n",
    "    elite_actions = []\n",
    "    for idx, actions in enumerate(actions_batch):\n",
    "        if idx in idxs:\n",
    "            elite_actions += actions\n",
    "    \n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 184.960, threshold=200.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a5a0bc364649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a5a0bc364649>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3dff37f026bc>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \"\"\"\n\u001b[1;32m   1058\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \"\"\"\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2182\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    sessions = [generate_session(agent) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    agent.partial_fit(elite_states, elite_actions, range(n_actions))\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session(agent) for _ in range(100)]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.2.5417.video000001.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "plt.imshow(visualize_mountain_car(env, agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
